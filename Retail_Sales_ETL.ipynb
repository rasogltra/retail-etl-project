{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "06e33b8e-fc47-44d7-b32e-cabcc2fa2467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging configured to write to: /home/jupyteruser/results/retail_reports/etl_app.log\n",
      "--- ETL Process Started ---\n",
      "Sucessfully created engine for database: /home/jupyteruser/data/retail/retail_db.db\n",
      "Processing file...\n",
      "Processing file...\n",
      "\n",
      " All CSV files processed and loaded.\n",
      "--- ETL Process Finished ---\n"
     ]
    }
   ],
   "source": [
    "# Retail Sales ETL (SQLite)\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import fnmatch\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "#--- Configurations ---\n",
    "DATABASE_NAME= 'retail_db.db'\n",
    "CSV_DATA_DIRECTORY = '/home/jupyteruser/data/retail/'\n",
    "REPORTS_DIRECTORY = '/home/jupyteruser/results/retail_reports/' \n",
    "\n",
    "# Configure logging to write to a file\n",
    "LOG_FILE_PATH = os.path.join(REPORTS_DIRECTORY, \"etl_app.log\")\n",
    "try:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, \n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers = [\n",
    "            logging.FileHandler(LOG_FILE_PATH, encoding= 'utf-8', mode='a') # Log to file\n",
    "        ]\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(f\"Logging configured to write to: {LOG_FILE_PATH}\")\n",
    "    print(f\"Logging configured to write to: {LOG_FILE_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR: Could not configure logging to '{LOG_FILE_PATH}'. Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "def loadData (df: pd.DataFrame, table_name: str, engine):\n",
    "    if table_name == 'products':\n",
    "        # Handle missing values and correcting data types for 'products'\n",
    "        df= df.replace({' ' : pd.NA, '': pd.NA}).copy() # Copy refers to a new dataframe, preventing issues\n",
    "\n",
    "        df['price'] = pd.to_numeric(df['price'], errors= 'coerce')\n",
    "        df['price']= df['price'].abs()\n",
    "\n",
    "        df['name'] = df['name'].str.strip().str.title().fillna('')\n",
    "        df['category'] = df['category'].str.strip().str.title().fillna('')\n",
    "     \n",
    "    elif table_name == 'sales':\n",
    "        df= df.replace({' ' : pd.NA, '': pd.NA}).copy() # Copy refers to a new dataframe, preventing issues\n",
    "\n",
    "        df['quantity'] = pd.to_numeric(df['quantity'], errors= 'coerce')\n",
    "\n",
    "        df['sales_date'] = pd.to_datetime(df['sales_date'], errors='coerce', dayfirst=False)\n",
    "\n",
    "    # --- Load dataframe into table_name ---\n",
    "    try:\n",
    "        df.to_sql(table_name, con=engine, if_exists= 'replace', index= False) # won't add index columns to SQL\n",
    "        logger.info(f\"Sucessfully inserted data into table: {table_name}.\") \n",
    "    except SQLAlchemyError as e:\n",
    "        logger.error(f\"Failed to load data into table {table_name}: {e}\")\n",
    "        print(f\"Failed to load data into table {table_namae}: {e}\") \n",
    "\n",
    "def readData(directory: str = CSV_DATA_DIRECTORY):\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        logger.error(f\"Error: Directory '{directory}' does not exist. Please ensure your CSV files are in this location.\")\n",
    "        print(f\"Error: Directory '{directory} does not exists. Please ensure your CSV fies are in this location.'\")\n",
    "        return None\n",
    "        \n",
    "    database_file_path= os.path.join(directory, DATABASE_NAME)\n",
    "\n",
    "    try:\n",
    "        engine= create_engine(f'sqlite:///{database_file_path}', echo=False)\n",
    "        logger.info(f\"Sucessfully created engine for database: {database_file_path}\")\n",
    "        print(f\"Sucessfully created engine for database: {database_file_path}\")\n",
    "        \n",
    "        for file in os.listdir(directory):\n",
    "            if fnmatch.fnmatch(file, '*.csv'):\n",
    "                table_name= file.split(\".\")[0]\n",
    "                fullpath = os.path.join(directory, file)\n",
    "\n",
    "                logger.info(f\"Processing: '{file}' for table '{table_name}'\")\n",
    "                print(f\"Processing file...\")\n",
    "                \n",
    "                try:\n",
    "                    df= pd.read_csv(fullpath)\n",
    "                    logger.info(f\"Read {len(df)} rows from '{file}'.\")\n",
    "                    \n",
    "                    df_cleaned= df.drop_duplicates()\n",
    "                    logger.info(f\"Dropped {len(df) - len(df_cleaned)} duplicate rows from {file}. Remaining rows: {len(df_cleaned)}.\")\n",
    "                    \n",
    "                    loadData(df_cleaned, table_name, engine)\n",
    "                    \n",
    "                except pd.errors.EmptyDataError as e:\n",
    "                    logger.warning(f\"CSV file '{file}' is empty. Skipping.\")\n",
    "                    print (f\"CSV file '{file}' is empty. Skipping.\")                      \n",
    "                except FileNotFoundError as e:\n",
    "                    logger.error(f\"{e}\")\n",
    "                    print(f\"{e}\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing file '{file}': {e}\")\n",
    "                    print(f\"Error processing file '{file}': {e}\")\n",
    "                    \n",
    "        print(\"\\n All CSV files processed and loaded.\")            \n",
    "        return engine\n",
    "        \n",
    "    except SQLAlchemyError as e:\n",
    "        logger.error(f\"Failed to open or connect to database: {e}\")\n",
    "        print(f\"Failed to open or connect to database: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occured during readData: {e}\")\n",
    "        print(f\"An unexpected error occured during readData: {e}\")\n",
    "        return None\n",
    "\n",
    "def queryData (engine):\n",
    "    if engine is None:\n",
    "        logger.error(\"Cannot query data: Database engine is not available.\")\n",
    "        print(\"Cannot query data: Database engine is not available.\")\n",
    "        return\n",
    "        \n",
    "    logger.info(\"\\n--- Starting querying and report generation ---\")\n",
    "\n",
    "    if not os.path.exists(REPORTS_DIRECTORY):\n",
    "        try: \n",
    "            os.makedirs(REPORTS_DIRECTORY)\n",
    "            print(f\"Created directory: {REPORTS_DIRECTORY}\")\n",
    "        except OSError as e:\n",
    "            logger.error(f\"Error creating reports directory '{REPORTS_DIRECTORY}': {e}\")\n",
    "            return\n",
    "            \n",
    "    try: \n",
    "        logger.info(\"Executing SQL query (1): Total Sales per Product\")\n",
    "        total_sales_query = text(\"\"\" \n",
    "            SELECT \n",
    "                name, \n",
    "                ROUND(SUM(a.price * quantity), 2) AS Total_Sales \n",
    "            FROM \n",
    "                products a \n",
    "            INNER JOIN \n",
    "                sales b ON a.product_id = b.product_id \n",
    "            GROUP BY \n",
    "                name\n",
    "            ORDER BY \n",
    "                Total_Sales DESC; \n",
    "        \"\"\")\n",
    "        \n",
    "        df_total_sales= pd.read_sql(total_sales_query, con=engine)\n",
    "        df_total_sales.to_csv(os.path.join(REPORTS_DIRECTORY, 'total_sales.csv'), index= False)\n",
    "\n",
    "        logger.info(\"Executing SQL query using pandas (2): Average price of sold products per Category\")\n",
    "        avg_price_query = text(\"\"\" \n",
    "            SELECT \n",
    "                category, \n",
    "                ROUND(AVG(a.price), 2) as Avg_Price_Per_Unit_Sold,\n",
    "                ROUND(SUM(a.price * b.quantity) / SUM(b.quantity), 2) As Weighted_Avg_Price_Sold\n",
    "            FROM \n",
    "                products a \n",
    "            JOIN \n",
    "                sales b ON a.product_id = b.product_id \n",
    "            GROUP BY \n",
    "                category\n",
    "            ORDER BY Weighted_Avg_Price_Sold DESC;\n",
    "        \"\"\")\n",
    "        \n",
    "        df_avg_price_query = pd.read_sql(avg_price_query, con= engine)\n",
    "        df_avg_price_query.to_csv(os.path.join(REPORTS_DIRECTORY, 'avg_price_per_category.csv'), index= False)\n",
    "        \n",
    "        logger.info(\"Executing SQL query using pandas (3): Best-Selling Category\")\n",
    "        best_selling_query = text(\"\"\" \n",
    "            SELECT \n",
    "                category, \n",
    "                ROUND(SUM(a.price * quantity), 2)  as Total_Sales \n",
    "            FROM \n",
    "                products a\n",
    "            INNER JOIN \n",
    "                sales b ON a.product_id = b.product_id\n",
    "            GROUP BY \n",
    "                category \n",
    "            ORDER BY \n",
    "                Total_sales DESC \n",
    "            LIMIT 1;\n",
    "        \"\"\")\n",
    "        \n",
    "        df_best_selling = pd.read_sql(best_selling_query, con=engine)\n",
    "        df_best_selling.to_csv(os.path.join(REPORTS_DIRECTORY, 'best_selling_category.csv'), index= False)\n",
    "        \n",
    "    except SQLAlchemyError as e:\n",
    "        logger.error(f\"Failed to query database: {e}\")\n",
    "        print (f\"Failed to query database: {e}\")  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- ETL Process Started ---\")\n",
    "    print(\"--- ETL Process Started ---\")\n",
    "    \n",
    "    # Read data from CSVs and load into database\n",
    "    # readData returns engine object\n",
    "    db_engine = readData(directory=CSV_DATA_DIRECTORY)\n",
    "\n",
    "    if db_engine:\n",
    "        queryData(engine=db_engine)\n",
    "    else:\n",
    "        logger.error(\"ETL process failed during data loading. Skipping queries.\")\n",
    "        print(\"ETL process failed during data loading. Skipping queries.\")\n",
    "\n",
    "    logger.info(\"--- ETL Process Finished ---\")\n",
    "    print(\"--- ETL Process Finished ---\")\n",
    "    logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca8210-56ae-4a4c-bc25-70b0aaa62946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
